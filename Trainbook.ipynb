{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T14:58:51.219161Z",
     "start_time": "2025-09-13T14:58:51.207470Z"
    }
   },
   "source": [
    "from bpe import BasicTokenizer\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.load(model_file='./output/tokenizer/tokenzier_v1.model')\n",
    "\n",
    "def get_vocab_size(tokenizer_param: BasicTokenizer):\n",
    "    return len(tokenizer_param.vocab) + len(tokenizer_param.special_tokens)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9e98e641b5d6f326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T14:58:54.497178Z",
     "start_time": "2025-09-13T14:58:52.920504Z"
    }
   },
   "source": [
    "import torch\n",
    "torch.manual_seed(3462)\n",
    "\n",
    "print(f\"PyTorch версия: {torch.__version__}\")\n",
    "print(f\"CUDA версия: {torch.version.cuda}\")\n",
    "print(f\"CuDNN версия: {torch.backends.cudnn.version()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch версия: 2.8.0+cu126\n",
      "CUDA версия: 12.6\n",
      "CuDNN версия: 91002\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e2686617acc49861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T14:58:59.548505Z",
     "start_time": "2025-09-13T14:58:58.180629Z"
    }
   },
   "source": [
    "from transformers import GPTLanguageModel\n",
    "\n",
    "block_size = 256\n",
    "n_embedding = 512\n",
    "n_head = 8\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "batch_size = 64\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embeddings=n_embedding,\n",
    "    n_head=n_head,\n",
    "    device=device,\n",
    "    n_layers=n_layer,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "device"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.79329 M parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "19899cf5aeefd6c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:27.663784Z",
     "start_time": "2025-09-13T14:59:01.978478Z"
    }
   },
   "source": [
    "with open('./output/text_corpus.txt', 'r', encoding='utf-8') as f:\n",
    "    text_corpus = f.read()\n",
    "\n",
    "encoded_text = tokenizer.encode(text_corpus)\n",
    "len(encoded_text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255729"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "5357da5e950bd87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:33.428373Z",
     "start_time": "2025-09-13T15:00:33.403986Z"
    }
   },
   "source": [
    "data = torch.tensor(encoded_text, dtype=torch.long)\n",
    "split_index = int(0.9*len(data))\n",
    "train_data = data[:split_index]\n",
    "valid_data = data[split_index:]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "105fdc86ae4d1df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:36.751213Z",
     "start_time": "2025-09-13T15:00:36.743511Z"
    }
   },
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size:int) -> None:\n",
    "        if len(data) <= block_size:\n",
    "            raise ValueError(\n",
    "                f'The length of the dataset ({len(data)}) must be greater than the block size ({block_size})'\n",
    "            )\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.block_size\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.data[index: index + self.block_size]\n",
    "        y = self.data[index + 1: index + self.block_size + 1]\n",
    "        return x, y\n",
    "\n",
    "def get_dataloader(train_data: torch.Tensor,\n",
    "                   valid_data: torch.Tensor,\n",
    "                   block_size: int,\n",
    "                   batch_size: int,\n",
    "                   device: torch.device) -> Tuple[DataLoader, DataLoader]:\n",
    "    train_dataset = TextDataset(train_data.to(device), block_size)\n",
    "    valid_dataset = TextDataset(valid_data.to(device), block_size)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "    return train_loader, valid_loader"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e3ca30e673a57754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:42.738591Z",
     "start_time": "2025-09-13T15:00:42.672231Z"
    }
   },
   "source": [
    "train_loader, valid_loader = get_dataloader(train_data=train_data,\n",
    "                                            valid_data=valid_data,\n",
    "                                            block_size=block_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            device=device)\n",
    "x,y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 256]), torch.Size([64, 256]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ec5917e0a3ca762b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:45.176862Z",
     "start_time": "2025-09-13T15:00:45.172324Z"
    }
   },
   "source": [
    "from typing import Dict\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "        model: torch.nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        valid_loader: DataLoader,\n",
    "        eval_iterations: int\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "    for split, loader in [('train', train_loader), ('valid', valid_loader)]:\n",
    "        loses = torch.zeros(eval_iterations)\n",
    "        for i, (x,y) in enumerate(loader):\n",
    "            if i >= eval_iterations:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x,y)\n",
    "            loses[i] = loss.item()\n",
    "        output[split] = loses.mean().item()\n",
    "\n",
    "    model.train()\n",
    "    return output\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "2ddca43330d93933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:47.824603Z",
     "start_time": "2025-09-13T15:00:47.821043Z"
    }
   },
   "source": [
    "def save_checkpoint(model: torch.nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    epoch: int,\n",
    "                    loss: float,\n",
    "                    file_path: str = 'checkpoint.pth'\n",
    "                    ) -> None:\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'loss': loss\n",
    "                  }\n",
    "    torch.save(checkpoint, file_path)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "53ae41eac5cce635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T04:50:10.586602600Z",
     "start_time": "2025-09-13T15:13:00.145237Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "max_iters = 1\n",
    "eval_interval = 100\n",
    "eval_iters = 200\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader, val_loader = get_dataloader(train_data=train_data,\n",
    "                                          valid_data=valid_data,\n",
    "                                          block_size=block_size,\n",
    "                                          batch_size=batch_size,\n",
    "                                          device=device)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            loss = estimate_loss(model,\n",
    "                                 train_loader,\n",
    "                                 val_loader,\n",
    "                                 min(eval_iters, len(val_loader))\n",
    "                                 )\n",
    "            train_losses.append(loss['train'])\n",
    "            valid_losses.append(loss['valid'])\n",
    "            print(f'iteration: {iteration} / step : {batch_idx}, '\n",
    "                  f'train_losses: {loss[\"train\"]:.4f},'\n",
    "                  f'valid_losses: {loss[\"valid\"]:.4f}'\n",
    "                  )\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    save_checkpoint(model,\n",
    "                    optimizer,\n",
    "                    iteration,\n",
    "                    loss.item(),\n",
    "                    file_path=f'./output/pretrain/v2/checkpoint_{iteration}.pth')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3593 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 0, train_losses: 0.2386,valid_losses: 6.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101/3593 [03:26<22:06:29, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 100, train_losses: 0.2213,valid_losses: 6.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 201/3593 [05:40<21:25:48, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 200, train_losses: 0.2102,valid_losses: 6.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 301/3593 [07:54<20:48:26, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 300, train_losses: 0.2023,valid_losses: 6.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 401/3593 [10:07<20:08:09, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 400, train_losses: 0.1934,valid_losses: 6.3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 501/3593 [12:21<19:31:50, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 500, train_losses: 0.1849,valid_losses: 6.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 601/3593 [14:38<19:34:38, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 600, train_losses: 0.1811,valid_losses: 6.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 701/3593 [16:54<18:33:18, 23.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 700, train_losses: 0.1748,valid_losses: 6.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 801/3593 [19:09<18:00:28, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 800, train_losses: 0.1708,valid_losses: 6.5823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 901/3593 [21:23<17:00:23, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 900, train_losses: 0.1647,valid_losses: 6.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1001/3593 [23:38<16:38:00, 23.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1000, train_losses: 0.1614,valid_losses: 6.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1101/3593 [25:56<16:25:43, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1100, train_losses: 0.1575,valid_losses: 6.7489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1201/3593 [28:13<15:37:40, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1200, train_losses: 0.1540,valid_losses: 6.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1301/3593 [30:29<14:38:21, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1300, train_losses: 0.1504,valid_losses: 6.8306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1401/3593 [32:44<13:58:39, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1400, train_losses: 0.1476,valid_losses: 6.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1501/3593 [34:59<13:22:32, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1500, train_losses: 0.1451,valid_losses: 6.9641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1601/3593 [37:14<12:42:33, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1600, train_losses: 0.1431,valid_losses: 6.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1701/3593 [1:07:44<274:57:53, 523.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 / step : 1700, train_losses: 0.1402,valid_losses: 7.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1779/3593 [1:08:32<18:59,  1.59it/s]     "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70c2dff9-320a-4bbf-be37-5e81da50ae97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T14:56:41.573820Z",
     "start_time": "2025-09-13T14:56:39.822551Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(valid_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      3\u001B[39m plt.figure(figsize=(\u001B[32m10\u001B[39m, \u001B[32m5\u001B[39m))\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m plt.plot(\u001B[43mtrain_losses\u001B[49m, label=\u001B[33m\"\u001B[39m\u001B[33mTrain Loss\u001B[39m\u001B[33m\"\u001B[39m, marker=\u001B[33m'\u001B[39m\u001B[33mo\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      5\u001B[39m plt.plot(valid_losses, label=\u001B[33m\"\u001B[39m\u001B[33mValidation Loss\u001B[39m\u001B[33m\"\u001B[39m, marker=\u001B[33m'\u001B[39m\u001B[33mo\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      6\u001B[39m plt.xlabel(\u001B[33m\"\u001B[39m\u001B[33mEvaluation Step\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:00:59.139169Z",
     "start_time": "2025-09-13T15:00:58.671841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_path = f'./output/pretrain/checkpoint_0.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ],
   "id": "3584d30c9ac1f473",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T15:12:11.260170Z",
     "start_time": "2025-09-13T15:12:09.767236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_tokens = tokenizer.encode('Привет')\n",
    "input_tokens = torch.tensor(input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens, 100)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))\n"
   ],
   "id": "7cff8e76aa7c9d38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приветросьба назад по видео. Ну высужно своих соседей. Тажется что кто-то голосует )Доброй ночи всегдачи! \\nМыездаю, что есть проблемы с ребенок не бегут на трубает \\nНапоминать, закрыли за чем я лично, а это свой счёт водой, только через прогул\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
